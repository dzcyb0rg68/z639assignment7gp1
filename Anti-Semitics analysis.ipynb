{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /u/cc93/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import json\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import zstandard as zstd\n",
    "import json\n",
    "import lzma\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = open('antisemitics.txt', 'w+') #hulu is ranked 3956\n",
    "head.write('%s\\t %s\\t %s\\t %s\\t %s\\t %s\\t %s\\t %s\\t %s\\t %s\\t\\n'% ('row number', 'subreddit' ,'author', 'date', 'socre' ,'word', 'datetime', 'distict_score', 'shared_word','comment'))\n",
    "head.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antisemitics_words = ['libel', 'clannish', 'conspiracy', 'cowardice', 'goyim', 'globalist', 'greed', 'holocaust', 'jew', 'jewish', 'illuminati', 'khazars', 'kosher', 'zionish', 'scapegoat', 'silencing', 'smirking', 'merchant']\n",
    "antisemitics_set = set(antisemitics_words)\n",
    "\n",
    "filenames = [\"/l/research/social-media-mining/reddit/comments/RC_2018-01.xz\"]\n",
    "i = 0\n",
    "\n",
    "\n",
    "for filename in filenames:\n",
    "    date = filename.replace('.xz','').replace('.zst','')\n",
    "    if filename.split('.',1)[1] == 'xz':\n",
    "        with lzma.open(filename, mode='rt', encoding='utf-8') as redditfile:\n",
    "            for line in redditfile:\n",
    "                line = json.loads(line)\n",
    "                words = re.findall(r'\\w+', line['body'].lower())\n",
    "                words_set = set(words)\n",
    "                common_elements = words_set.intersection(antisemitics_set)\n",
    "                score = len(common_elements)\n",
    "                antisemitics_list = []\n",
    "                if score >= 1:\n",
    "                    for w in words:\n",
    "                        for a in antisemitics_words:\n",
    "                            if w == a:\n",
    "                                antisemitics_list.append(w)\n",
    "                                \n",
    "                    ndate = datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=(line['created_utc']))\n",
    "                    ndate = ndate.isoformat().replace('T',' ')\n",
    "                    file = open('antisemitics.txt', 'a+')\n",
    "                    file.write('%d\\t %s\\t %s\\t %s\\t %d\\t %s\\t %s\\t %d\\t %s\\t %s\\t\\n'% (i+1, line['subreddit'], line['author'].replace('\\n',''), date[-7:], len(antisemitics_list), antisemitics_list, ndate, score, list(dict.fromkeys(antisemitics_list)), line['body'].replace('\\n','')))\n",
    "                    i += 1\n",
    "                    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def convert_sectodate(sec):\n",
    "    ndate = datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=(sec))\n",
    "    return ndate.isoformat().replace('T',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dict = {'all_awardings': [],\n",
    "#  'author': 'ragenukem',\n",
    " 'author_created_utc': 1343369985,\n",
    " 'author_flair_background_color': None,\n",
    " 'author_flair_css_class': None,\n",
    " 'author_flair_richtext': [],\n",
    " 'author_flair_template_id': None,\n",
    " 'author_flair_text': None,\n",
    " 'author_flair_text_color': None,\n",
    " 'author_flair_type': 'text',\n",
    " 'author_fullname': 't2_8gva8',\n",
    " 'author_patreon_flair': False,\n",
    "#  'body': 'I get to do the thing! /r/beetlejuicing',\n",
    " 'can_gild': True,\n",
    " 'can_mod_post': False,\n",
    " 'collapsed': False,\n",
    " 'collapsed_reason': None,\n",
    " 'controversiality': 0,\n",
    " 'created_utc': 1559347203,\n",
    " 'distinguished': None,\n",
    " 'edited': False,\n",
    " 'gilded': 0,\n",
    " 'gildings': {},\n",
    " 'id': 'epom0fx',\n",
    " 'is_submitter': False,\n",
    " 'link_id': 't3_bv9v53',\n",
    " 'locked': False,\n",
    " 'no_follow': True,\n",
    " 'parent_id': 't1_epobwr9',\n",
    " 'permalink': '/r/Wellthatsucks/comments/bv9v53/ball_boy_meet_wall_boy/epom0fx/',\n",
    " 'quarantined': False,\n",
    " 'removal_reason': None,\n",
    " 'retrieved_on': 1568677948,\n",
    "#  'score': 2,\n",
    "#  'send_replies': True,\n",
    " 'steward_reports': [],\n",
    " 'stickied': False,\n",
    "#  'subreddit': 'Wellthatsucks',\n",
    " 'subreddit_id': 't5_2xcv7',\n",
    " 'subreddit_name_prefixed': 'r/Wellthatsucks',\n",
    " 'subreddit_type': 'public',\n",
    " 'total_awards_received': 0}\n",
    "\n",
    "def remove_key(target_dict, source_dict):\n",
    "    for key in source_dict:\n",
    "        try:\n",
    "            del target_dict[key]\n",
    "        except KeyError:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "antisemitics_words = ['libel', 'clannish', 'conspiracy', 'cowardice', 'goyim', 'globalist', 'greed', 'holocaust', 'jew', 'jewish', 'illuminati', 'khazars', 'kosher', 'zionish', 'scapegoat', 'silencing', 'smirking', 'merchant']\n",
    "antisemitics_set = set(antisemitics_words)\n",
    "\n",
    "filenames = [\"/l/research/social-media-mining/reddit/comments/RC_2018-01.xz\"]\n",
    "\n",
    "for filename in filenames:\n",
    "    date = filename.replace('.xz','').replace('.zst','')\n",
    "    if filename.split('.',1)[1] == 'xz':\n",
    "        with lzma.open(filename, mode='rt', encoding='utf-8') as redditfile:\n",
    "            for line in redditfile:\n",
    "                line = json.loads(line)\n",
    "                words = re.findall(r'\\w+', line['body'].lower())\n",
    "                words_set = set(words)\n",
    "                common_elements = words_set.intersection(antisemitics_set)\n",
    "                score = len(common_elements)\n",
    "                antisemitics_list = []\n",
    "                if score >= 1:\n",
    "                    for w in words:\n",
    "                        for a in antisemitics_words:\n",
    "                            if w == a:\n",
    "                                antisemitics_list.append(w)\n",
    "                                \n",
    "                    ndate = convert_sectodate(line['created_utc'])\n",
    "                    line['date_year_month'] = date[-7:]\n",
    "                    line['created_utc_converted'] = ndate\n",
    "                    line['score_overall'] = len(antisemitics_list)\n",
    "                    line['words'] = ' '.join([str(elem) for elem in antisemitics_list])\n",
    "                    line['shared_words'] = ' '.join([str(elem) for elem in list(dict.fromkeys(antisemitics_list))])\n",
    "                    line['socre_distint'] = score\n",
    "                    remove_key(line, sample_dict)\n",
    "                    with open('antisemitics.json', 'a') as outfile:\n",
    "                        json.dump(line, outfile)\n",
    "                        outfile.write('\\n')\n",
    "                        outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'ragenukem',\n",
       " 'body': 'I get to do the thing! /r/beetlejuicing',\n",
       " 'score': 2,\n",
       " 'send_replies': True,\n",
       " 'subreddit': 'Wellthatsucks'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaaa = json.loads('{\"author\":\"ragenukem\",\"author_created_utc\":1343369985,\"author_flair_background_color\":null,\"author_flair_css_class\":null,\"author_flair_richtext\":[],\"author_flair_template_id\":null,\"author_flair_text\":null,\"author_flair_text_color\":null,\"author_flair_type\":\"text\",\"author_fullname\":\"t2_8gva8\",\"author_patreon_flair\":false,\"body\":\"I get to do the thing! \\/r\\/beetlejuicing\",\"can_gild\":true,\"can_mod_post\":false,\"collapsed\":false,\"collapsed_reason\":null,\"controversiality\":0,\"created_utc\":1559347203,\"distinguished\":null,\"edited\":false,\"gilded\":0,\"gildings\":{},\"id\":\"epom0fx\",\"is_submitter\":false,\"link_id\":\"t3_bv9v53\",\"locked\":false,\"no_follow\":true,\"parent_id\":\"t1_epobwr9\",\"permalink\":\"\\/r\\/Wellthatsucks\\/comments\\/bv9v53\\/ball_boy_meet_wall_boy\\/epom0fx\\/\",\"quarantined\":false,\"removal_reason\":null,\"retrieved_on\":1568677948,\"score\":2,\"send_replies\":true,\"steward_reports\":[],\"stickied\":false,\"subreddit\":\"Wellthatsucks\",\"subreddit_id\":\"t5_2xcv7\",\"subreddit_name_prefixed\":\"r\\/Wellthatsucks\",\"subreddit_type\":\"public\",\"total_awards_received\":0}')\n",
    "remove_key(aaaaa, sample_dict)\n",
    "aaaaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
